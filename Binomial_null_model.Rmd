```{r}
library(rjags, lib.loc = "/share/pkg.7/r/3.6.0/install/lib64/R/library")
library(lazyeval, lib.loc = "/share/pkg.7/r/3.6.0/install/lib64/R/library")
library(ggplot2, lib.loc = "/share/pkg.7/r/3.6.0/install/lib64/R/library")
library(coda, lib.loc = "/share/pkg.7/r/3.6.0/install/lib64/R/library")
library(dplyr, lib.loc = "/share/pkg.7/r/3.6.0/install/lib64/R/library")
```
# Load data
```{r}
tick_disease_big <- read.csv("/usr3/graduate/tmccabe/Maine_Tick_Disease_Forecast/town_level_data_lyme.csv", header = TRUE, stringsAsFactors = FALSE)

tick_disease_big$Population <- gsub(pattern = ",", replacement = "", tick_disease_big$Population)

towns_in_cumberland <- c("Harpswell", "Freeport", "Brunswick", "Pownal", "Frye_Island", "Yarmouth", 
                         "Cumberland", "Standish", "Chebeague_Island", "Portland", "Falmouth", "South_Portland", 
                         "Cape_Elizabeth", "Long_Island", "Scarborough", "Harrison", "Gray", "North_Yarmouth", 
                         "Baldwin", "Bridgton", "Casco", "Raymond", "Naples", "Sebago", "Windham", "Gorham",
                         "Westbrook", "New_Gloucester")
unique(tick_disease_big$Number)

towns_for_validation <- c("Bridgton","Sebago",  "Westbrook")

towns_to_run <- towns_in_cumberland[!(towns_in_cumberland %in% towns_for_validation)]

## Correct names for spacing
tick_disease_big$Location <- gsub(" ", "_", tick_disease_big$Location)
tick_disease <- tick_disease_big[tick_disease_big$Location %in% towns_in_cumberland, ]

tick_disease_big$Location <- gsub(" ", "_", tick_disease_big$Location)
tick_disease <- tick_disease_big[tick_disease_big$Location %in% towns_in_cumberland, ]




```

## A Binomial null model

This Binomial null model models having lyme as a binomial process twice. The first time is a model of detection probability, which says the the number of observed cases is a function of some probability of detecting lyme in a patient, and the "true" number of lyme cases is the number of trials fed into the binomial disitrbution. The second time is modeling the incidence of lyme in a town as a fucntion of population of that town. We say that each per-year-person has some probability of contracting lyme disease. 

## Developing priors

# Prior on error levels of underreporting (a_obs, b_obs)

The full data model is what translates the observed CDC data `y[]` into the latent state `x[]`. The latent state is meant to represent a "true" number of lyme cases, with an understanding that the reported lyme cases are underreported. The data model aproximates the latent state based on the observed state. This means that crafting a data model requires knowing how/why cases are underreported. 

Cases of disease are undereported for a variaety of interacting reasons, including access to medical care/ testing facilities, awareness of disease, cost of medical treatment, false negatives in testing, misdiagnosis etc.

Having an error term that encoumpassed all those reasons for underreporting would be ideal, but there are very few papers that provide numerical estimates for all of the above reasons. Some papers have estimated error rates in blood-sample-testing, and diagnosis rates (see below). 

We wanted to have a CDC-provided estimate of the error to put into the prior, but also anouther estimate to benchmark our modeled output against. Ideally, the prior would be set by a more general estimate of the error, and we could then benchmark against Maine-level estimates. 

Currently, the plan is to make a prior based on the Hinckley et al paper, and have our model be predicting the number of people with lyme disease that were tested, but got a negative result. The two gate-keepers for tick disease reporting to the CDC are positive lab results, and identification of symptoms (rash/ clinicaly defined symotoms) and diagnosis by a medical profesional. Out data model will constrain false negatives from the blood lab results, but that will not constrain uderreporting assosiated with access to lab-testing, accesing the medical community, or underreporting within the medical community. We also don't deal with false positives within testing becuase the CDC criteria for reporting has a high level of certainty.


Hinckley et al paper reports a "True positive rate" of the number of samples sent for testing, and an "observed" positive rate for two tests . I am not sure what type of assay is used in the labs that inform Maine incident reports, but two types are reported in the Hinckley et al: the Two-tiered whole cell test, and the EIA/IFA stand-alone or first tier test. They also report the proportion of the samples that were tested useing those two tests, so we will assume the same proportions (Table 3 of Hinckley et al).

```{r}
# reprted "true positive" is 0.12 with range of 0.1 to 0.185. With rate of 0.12,  288 000 cases were reported ( range of 240000 - 444000. 


estBetaParams <- function(mu, var) {
  alpha <- ((1 - mu) / var - 1 / mu) * mu ^ 2
  beta <- alpha * (1 / mu - 1)
  return(params = list(alpha = alpha, beta = beta))
}

mu_true_pos <- 0.12
observed_pos_1 <- 0.0579 # Two Tier
observed_pos_2 <- 0.1189 # EIA/ IFA Stand-alone or First Tier
proportion_used_1 <- 297619/ (297619 + 287595)  # Reported number of tests for two-tierd / total 
proportion_used_2 <- 287595/ (297619 + 287595) # Reported number of tests for two-tierd / total 

weighted_obs_pos <- (0.0579 *proportion_used_1) + (0.1189*proportion_used_2)

detection_rate_mu <- weighted_obs_pos / mu_true_pos
detection_rate_min <-  weighted_obs_pos / 0.185
detection_rate_max <- weighted_obs_pos / 0.1

var_true_pos <- 0.11 # Something larger than min and max, but still constrained by them. 

beta_of_true_tick_rate <- estBetaParams(detection_rate_mu, var_true_pos)

```


# A prior on yearly_error

The parameter yearly_error represents the error in tick counts year to year. We estimated this based on non-cumberland data 2008-2018. 



```{r}
## Find year to year variation for each town
towns_in_rest_of_maine <- unique(tick_disease_big$Location)
variations <- c()
for (i in seq_along(towns_in_rest_of_maine)){
  
  town_name <- towns_in_rest_of_maine[i]
  tick_data <- tick_disease_big

  tick_disease_tmp <- tick_data[(tick_data$Location == town_name ),] 
  tick_disease_tmp <- dplyr::filter(tick_disease_tmp, tick_disease_tmp$Year >= 2008)
  tick_disease_tmp <- dplyr::filter(tick_disease_tmp, tick_disease_tmp$Year < 2016) 
  
  print(town_name)
  for(j in 1:(length(tick_disease_tmp$Year-1))){
    
    is_numeric_j <- try(as.numeric(tick_disease_tmp$Number[j]))
    is_numeric_j_next <- try(as.numeric(tick_disease_tmp$Number[j + 1]))
    
    if(!is.na(is_numeric_j) && !is.na(is_numeric_j_next)){
      diff <- as.numeric(tick_disease_tmp$Number[j]) - as.numeric(tick_disease_tmp$Number[j + 1])
      #print(diff)
    }else{
      #print(".....Skipping.....")
      next  ## skip over all year-year variablility in suppressed data.  Imperfect. 
    }
    
    variations <- c(variations, diff)
  }
  
}

## Take mean of that distribution
#hist(variations)
mean_year_year_variability <- mean(variations) ## What to plug into the poission 

```


# A prior on x_ic

This parameter represents the latent state of the system in 2008. Using the negative binomial to aproximate the latent varible. The negative binomial returns the number of failures that occur before a certain number of successes, where the probability of success is detection_rate_mu. We are looking at observations which we are presuming are the result of a binomial process where the number of trials is the true number of lyme disease incidents. To get back that number of trials from observations, we need to get the number of failures (the result of a random draw from the negative binomial) and add that to the number of sucesses (The observations). 


```{r}
## Declare matrix to store x_ic values per town
town_x_ic <- matrix(nrow = length(towns_to_run), ncol = 2)
town_x_ic <- as.data.frame(town_x_ic)
names(town_x_ic) <- c("Location", "x_ic")


## Cycle through towns and do a random pull from negative binomial 
for (i in seq_along(towns_to_run)){
  town_name <- towns_to_run[i]
  tick_data <- tick_disease

  tick_disease_tmp <- tick_data[(tick_data$Location == town_name ),] 
  tick_disease_tmp <- dplyr::filter(tick_disease_tmp, tick_disease_tmp$Year == 2008)
  
  is_numeric <- try(as.numeric(tick_disease_tmp$Number))
  
  if(!is.na(is_numeric)){
    obs_ticks <- is_numeric  # Correct for difference in sampling. 
  }else{
    obs_ticks <- rpois(1, 1)
    if(obs_ticks > 5){ obs_ticks <- 5} # We know not larger than 5
  }
  if(obs_ticks < 1){ obs_ticks <- 0.1} # nbinom not accept 0's. Assign small non-zero number
  town_x_ic$Location[i] <- town_name
  town_x_ic$x_ic[i] <- (rnbinom(1, obs_ticks, detection_rate_mu) +obs_ticks) # add number of successes to number of failure to get total number of trials
  town_x_ic$x_ic <- floor(town_x_ic$x_ic) # Take care of 0.1 case
}

#town_x_ic$x_ic <- town_x_ic$x_ic 
```

```{r}
fit_binomial_null <- function(tick_data, has_suppressed = TRUE, town_name, n.iter = 91000, data_list, init_detection_rate,init_ic ){
  
  tick_data <- dplyr::arrange(tick_data, by = tick_data$Year) # Make sure to be going in order of year
   
  
  less_than_six_indices <- which(tick_data$Number == "<6" )
  numeric_indices <- which(tick_data$Number != "<6")
  
  data_list$n <- length(tick_data$Year) 
  data_list$numeric_indices <- numeric_indices
  data_list$less_than_six_indices <- less_than_six_indices
  data_list$y <- tick_data$Number
  
  ## Check if has suppressed data. If yes, provide flow control
  if (rlang::is_empty(less_than_six_indices)){
   has_suppressed <- FALSE
  }
  
  if(has_suppressed){
    RandomWalk = "
model{
  
  #### Data Model
  for(t in numeric_indices){
   
   y[t] ~ dbinom(detection_rate, x[t])
 }
 
  for(t in less_than_six_indices){   ## Maybe consider a population cutoff, and allow zeros
   y[t] ~ dbinom(detection_rate, x[t]) T(1,5)
  }

  #### Process Model
   for (i in 2:n){
   x[i] ~ dbinom(probability, pop[i])
  }

  ## Prior
  probability ~ dbeta(1,1) #uniform probability
  
  #### Priors
  x[1] ~ dpois(x_ic) 
  detection_rate ~ dbeta(a_obs,b_obs) 

}
"
  }else{
        RandomWalk = "
model{
  
  #### Data Model
  for(t in numeric_indices){
   y[t] ~ dbinom(detection_rate, x[t])
  }

  #### Process Model
   for (i in 2:n){
   x[i] ~ dbinom(probability, pop[i])
  }

  
  #### Priors
  x[1] ~ dpois(x_ic)
  detection_rate ~ dbeta(a_obs, b_obs)
  probability ~ dbeta(1,1) #uniform probability
}
"
  }

## loading in priors
#data <- data_list

## setting  initial conditions
nchain = 3
init <- list()
for(i in 1:nchain){
  init[[i]] <- list( detection_rate <- init_detection_rate , x_ic <- init_ic) # Maybe check  these 
}


j.model   <- jags.model (file = textConnection(RandomWalk),
                             data = data_list,
                             #inits = init,
                             n.chains = 3)

jags.out   <- coda.samples (model = j.model,
                            variable.names = c( "x", "detection_rate", "probability"),
                                n.iter = n.iter)

GBR <- gelman.plot(jags.out)
burnin <- GBR$last.iter[tail(which(apply(GBR$shrink[,,2]>1.05,1,any)),1)+1] ## Cut our burn-in. 

if(is.na(burnin)){
  warning("GBR !< 1.05. Model may have failed to converge")
  jags.burn <- jags.out
  did_it_converge <- "convergence_failed_GBR_test" 
  
}else{
  did_it_converge <- "convergence_passed_GBR_test"
  jags.burn <- window(jags.out,start=burnin, extend = FALSE)
}
  date_stamp <- Sys.time()
  date_stamp <- format(date_stamp, "%Y%m%d")
  file_name <- paste("/Users/tess/Documents/work/Maine_Tick_Disease_Forecast/Jags_output/", date_stamp, ".", "binomial_null",".",town_name,".", did_it_converge, ".","JAGS_run.Rdata", sep = "")
  print(did_it_converge)
  print(effectiveSize(jags.burn))
  #save(jags.burn, file = file_name )
  return(jags.burn)
}
```


## Looping over every town in cumberland 

note: Frye_Island is failing to converge, becuase a special case of data. Long_Island also failing to converge.  
note: Frye_Island is failing to converge, becuase a special case of data. Long_Island also failing to converge.  
```{r}
# Special children, failed to converge for maybe structural reasons: c("Pownal", "Harrison", "Baldwin")
## Converged: "Portland",  "Standish", "Cape_Elizabeth", "Scarborough", "Gorham", "New_Gloucester"
## Still more : "Chebeague_Island", "Long_Island" 
towns_to_run <- c("Chebeague_Island", "Long_Island", "Bridgton" , "Sebago"   , "Westbrook","Pownal", "Harrison", "Baldwin") # no Frye_Island because NA in data
for (i in seq_along(towns_to_run)){
  
 town_name <- towns_to_run[i]
tick_data <- tick_disease
  tick_disease_tmp <- tick_data[(tick_data$Location == town_name ),] 
  tick_disease_tmp <- dplyr::filter(tick_disease_tmp, tick_disease_tmp$Year > 2008) # Used 2008 as prior on system
  tick_disease_tmp$Number[tick_disease_tmp$Year > 2016] <- NA # Hold out three years for validation. 
  tick_disease_tmp <- dplyr::arrange(tick_disease_tmp, by = tick_disease_tmp$Year) # Make sure model is fitting through time
  
tick_data <- tick_disease_tmp
data_list <- list(less_than_six_indices = points_of_less_than_six, numeric_indices =numeric_indices, n = 7, a_obs = beta_of_true_tick_rate$alpha, b_obs = beta_of_true_tick_rate$beta , y = tick_disease_tmp$Number,  x_ic = town_x_ic$x_ic[town_x_ic$Location == town_name] , pop = as.numeric(tick_disease_tmp$Population))
print(town_name)
output <- fit_binomial_null(tick_data, has_suppressed = TRUE, town_name, n.iter = 11051000, data_list, init_detection_rate = 0.9, init_ic = as.numeric(tick_data$Number[1]) )
  
}
```