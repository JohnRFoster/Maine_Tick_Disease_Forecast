---
title: "Random_walk"
author: "Tempest McCabe"
date: "7/2/2019"
output: html_document
---

```{r}
library(rjags)
library(coda)
library(ggplot2)
library(dplyr)
```

## The Random-walk null model

The null random walk model we used is a 

## Developing priors

# Prior on error levels of underreporting (a_obs, b_obs)

The full data model is what translates the observed CDC data `y[]` into the latent state `x[]`. The latent state is meant to represent a "true" number of lyme cases, with an understanding that the reported lyme cases are underreported. The data model aproximates the latent state based on the observed state. This means that crafting a data model requires knowing how/why cases are underreported. 


Cases of disease are undereported for a variaety of interacting reasons, including access to medical care/ testing facilities, awareness of disease, cost of medical treatment, false negatives in testing, misdiagnosis etc.

Having an error term that encoumpassed all those reasons for underreporting would be ideal, but there are very few papers that provide numerical estimates for any spcific one. Some papers have estimated error rates in tick-testing, and diagnosis rates (see below). 

We wanted to have a CDC-provided estimate of the error to put into the prior, but also anouther estimate to benchmark our modeled output against. Ideally, the prior would be set by a more general estimate of the error, and we could then benchmark against Maine-level estimates. 

Currently, the plan is to make a prior based on the Hinckley et al paper, and have our model be predicting the number of people with lyme disease that were tested, but got a negative result. The two gate-keepers for tick disease reporting to the CDC are positive lab results, and identification of symptoms (rash/ clinicaly defined symotoms) and diagnosis by a medical profesional. Out data model will constrain false negatives from the tick lab results, but that will not constrain uderreporting assosiated with access to lab-testing, accesing the medical community, or underreporting within the medical community. We also don't deal with false positives within testing becuase the CDC criteria for reporting has a high level of certainty.


Hinckley et al paper reports a "True positive rate" of the number of ticks sent for testing. 
```{r}
# reprted "true positive" is 0.12 with range of 0.1 to 0.185. With rate of 0.12,  288 000 cases were reported ( range of 240000 - 444000. 


estBetaParams <- function(mu, var) {
  alpha <- ((1 - mu) / var - 1 / mu) * mu ^ 2
  beta <- alpha * (1 / mu - 1)
  return(params = list(alpha = alpha, beta = beta))
}

mu_true_pos <- 0.12
var_true_pos <- 0.03 # Something larger than 0.1 and 0.18, but still constrained by paper
beta_of_true_tick_rate <- estBetaParams(0.12, 0.03)

```


# A prior on yearly_error

The parameter yearly_error represents the error in tick counts year to year. We estimated this based on non-cumberland data 2008-2018. 

```{r}
## Find year to year variation for each town
towns_in_rest_of_maine <- unique(tick_disease_big$Location)
variations <- c()
for (i in seq_along(towns_in_rest_of_maine)){
  
  town_name <- towns_in_rest_of_maine[i]
  tick_data <- tick_disease_big

  tick_disease_tmp <- tick_data[(tick_data$Location == town_name ),] 
  tick_disease_tmp <- dplyr::filter(tick_disease_tmp, tick_disease_tmp$Year >= 2008)
  tick_disease_tmp <- dplyr::filter(tick_disease_tmp, tick_disease_tmp$Year < 2016) 
  
  print(town_name)
  for(j in 1:(length(tick_disease_tmp$Year-1))){
    
    is_numeric_j <- try(as.numeric(tick_disease_tmp$Number[j]))
    is_numeric_j_next <- try(as.numeric(tick_disease_tmp$Number[j + 1]))
    
    if(!is.na(is_numeric_j) && !is.na(is_numeric_j_next)){
      diff <- as.numeric(tick_disease_tmp$Number[j]) - as.numeric(tick_disease_tmp$Number[j + 1])
      #print(diff)
    }else{
      #print(".....Skipping.....")
      next  ## skip over all year-year variablility in suppressed data.  Imperfect. 
    }
    
    variations <- c(variations, diff)
  }
  
}

## Take mean of that distribution
hist(variations)
mean_year_year_variability <- mean(variations) ## What to plug into the poission 

```

# A prior on x_ic

This parameter represents the latent state of the system in 2007. Because 2007 was a year that the nature of case-definitions changed, the `y[2007]` means something different than the `y[2008]`. To put a somewhat informed prior on x_ic, I am plugging in 2007 data multiplied by 1.2 . This is about the amount two scientists familiar with the data said difference between the data was. 

```{r}
## Declare matrix to store x_ic values per town
town_x_ic <- matrix(nrow = length(towns_to_run), ncol = 2)
town_x_ic <- as.data.frame(town_x_ic)
names(town_x_ic) <- c("Location", "x_ic")

## Cycle through towns and do a random pull from negative binomial (I think the negative binomial is apropriate here)

for (i in seq_along(towns_to_run)){
  town_name <- towns_to_run[i]
  tick_data <- tick_disease

  tick_disease_tmp <- tick_data[(tick_data$Location == town_name ),] 
  tick_disease_tmp <- dplyr::filter(tick_disease_tmp, tick_disease_tmp$Year == 2007)
  
  is_numeric <- try(as.numeric(tick_disease_tmp$Number))
  
  if(!is.na(is_numeric)){
    obs_ticks <- is_numeric * 1.2 # Correct for difference in sampling. 
  }else{
    obs_ticks <- rpois(1, 1)
    if(obs_ticks > 5){ obs_ticks <- 5} # We know not larger than 5
    obs_ticks <- obs_ticks * 1.2
  }
  if(obs_ticks < 1){ obs_ticks <- 0.0001} # nbinom not accept 0's. Assign small non-zero number
  town_x_ic$Location[i] <- town_name
  town_x_ic$x_ic[i] <- rnbinom(1, obs_ticks, 0.12) # Prior
}


```


## A function that runs the model
```{r}

# For binom error
data_list <- list(less_than_six_indices = points_of_less_than_six, numeric_indices =numeric_indices, n = 9, a_obs = beta_of_true_tick_rate$alpha, b_obs = beta_of_true_tick_rate$beta , a_add = 2, r_add = 0.5,  y = tick_disease_tmp$Number,  x_ic = 87 , tau_ic = 1,yearly_error = 2)

town_name <- "Baldwin"
tick_data <- tick_disease

  tick_disease_tmp <- tick_data[(tick_data$Location == town_name ),] 
  tick_disease_tmp <- dplyr::filter(tick_disease_tmp, tick_disease_tmp$Year >= 2008)
  tick_disease_tmp <- dplyr::filter(tick_disease_tmp, tick_disease_tmp$Year < 2016) # Hold out three years for validation. 
  tick_disease_tmp <- dplyr::arrange(tick_disease_tmp, by = tick_disease_tmp$Year) # Make sure model is fitting through time

fit_random_walk <- function(tick_data, has_suppressed = TRUE, town_name, n.iter = 91000, data_list){
  
  tick_data <- dplyr::arrange(tick_data, by = tick_data$Year) # Make sure to be going in order of year
   
  
  less_than_six_indices <- which(tick_data$Number == "<6" )
  numeric_indices <- which(tick_data$Number != "<6")
  
  data_list$n <- 1 + length(tick_data$Year)
  data_list$numeric_indices <- numeric_indices
  data_list$less_than_six_indices <- less_than_six_indices
  data_list$y <- tick_data$Number
  
  ## Check if has suppressed data. If yes, provide flow control
  if (rlang::is_empty(less_than_six_indices)){
   has_suppressed <- FALSE
  }
  
  if(has_suppressed){
    RandomWalk = "
model{
  
  #### Data Model
  for(t in numeric_indices){
   
   y[t] ~ dbinom(true_positive, x[t])
 }
 
  for(t in less_than_six_indices){   ## Maybe consider a population cutoff, and allow zeros
   y[t] ~ dbinom(true_positive, x[t]) T(1,5)
  }

  #### Process Model
  for(t in 2:n){
    tmp[t] ~ dbern(0.5)
    error[t] ~ dpois(yearly_error)
    direction[t] <- 2*tmp[t] - 1 # Making Rademacher dist
    step_direction[t] <- direction[t] * error[t]

    z[t] ~ dpois(x[t-1])
    x[t] <-  z[t] + step_direction[t]
  }
  
  #### Priors
  x[1] ~ dpois(x_ic) 
  true_positive ~ dbeta(a_obs,b_obs) 

}
"
  }else{
        RandomWalk = "
model{
  
  #### Data Model
  for(t in numeric_indices){
   y[t] ~ dbinom(true_positive, x[t])
  }

  #### Process Model
  for(t in 2:n){
    
     ### Generate discrete random walk
    tmp[t] ~ dbern(0.5)
    error[t] ~ dpois(yearly_error)
    direction[t] <- 2*tmp[t] - 1 # Making Rademacher dist
    step_direction[t] <- direction[t] * error[t]

    z[t] ~ dpois(x[t-1])
    x[t] <-  z[t] + step_direction[t]
  }
  
  #### Priors
  x[1] ~ dpois(x_ic)
  true_positive ~ dbeta(a_obs, b_obs)

}
"
  }

## loading in priors
#data <- data_list

## setting  initial conditions
nchain = 3
init <- list()
for(i in 1:nchain){
  init[[i]] <- list( tau_obs <- 4, x_ic <- 10) # Maybe check  these 
}


j.model   <- jags.model (file = textConnection(RandomWalk),
                             data = data_list,
                             #inits = init,
                             n.chains = 3)

jags.out   <- coda.samples (model = j.model,
                            variable.names = c( "x", "true_positive"),
                                n.iter = n.iter)

GBR <- gelman.plot(jags.out)
burnin <- GBR$last.iter[tail(which(apply(GBR$shrink[,,2]>1.05,1,any)),1)+1] ## Cut our burn-in. 

if(is.na(burnin)){
  warning("GBR !< 1.05. Model may have failed to converge")
  jags.burn <- jags.out
  did_it_converge <- "convergence_failed_GBR_test" 
  
}else{
  did_it_converge <- "convergence_passed_GBR_test"
  jags.burn <- window(jags.out,start=burnin, extend = FALSE)
}
  date_stamp <- Sys.time()
  date_stamp <- format(date_stamp, "%Y%m%d")
  file_name <- paste("/Users/tess/Documents/work/Maine_Tick_Disease_Forecast/Jags_output/", date_stamp, ".", "random_walk",".",town_name,".", did_it_converge, ".","JAGS_run.Rdata", sep = "")
  print(did_it_converge)
  print(effectiveSize(jags.burn))
  #save(jags.burn, file = file_name )
  #return(jags.burn)
}


```


# Lit review for error rates in Tick reporting

*National Estimates of Errors*

Some national error estimates include [this paper](https://academic.oup.com/cid/article/59/5/676/2895755) by Hinckley et al, which estimates the "true" number of infections in 2008 based on the number of specimines sent into labs, and correcting for false positives and false negatives. It does not estimate the number of incidences where the tick itself was not sent in for testing, but says this could add to the number. 
[This CDC summary](https://www.cdc.gov/mmwr/volumes/66/ss/ss6622a1.htm?s_cid=ss6622a1_w) of the 2008-2015 data notes that tick disease rates are underreported in high-incidence areas but possibly over-reported in low-incidence areas.
  Starting in 2008, the CDC explicitly notes the difference between confirmed cases and probable cases. This difference could be used to estimate some of the error, but is also likely an underestimate because the definition of "probable case" still involves some positive lab results/ medical diagnosis. 

[This estimate](https://www.ncbi.nlm.nih.gov/pmc/articles/PMC4550147/) of 2005-2010 national incidence rate useing health insurence claims also argues for large numbers of underreporting. 

[This review](https://www-sciencedirect-com.ezproxy.bu.edu/science/article/pii/S0891552015000240?via%3Dihub) as well as being a thourough general review of lyme in the united states, summerizes some of the liturature attemting to estimate the amount of underreporting in lyme disease, putting it aproximatly 3-12 fold differences. The studies were state/ town specific but the techniqes used were: 
 - In Westchestesr New York a "determinisitc model with plausible ranges" [was used](https://academic.oup.com/aje/article/148/10/1018/135572) to estimate "true" incidence levels. 
 - Connecticut Physicians [were surveyed](https://europepmc.org/abstract/med/10186700).
 - Maryland Physicians [were surveyed](https://doi.org/10.1093/infdis/173.5.1260)
 -  Medical records in Wisconsin [were reviewd](https://academic.oup.com/aje/article/155/12/1120/123221)
 
*Maine Estimates of errors*

[There are 2011-2016 estimates of prevelance](https://data.mainepublichealth.gov/tracking/metadata-lyme-prevalence) by town in Maine. Because Prevelance = Incidence x Average duration of disease, we may be able to compare our estimates to prevelance data as measured by the survey. However, prevelance is estimated by the question "Have you ever been told by a doctor, nurse, or other health professional that you have Lyme disease?”. This question does not capture populations that would not have intereacted with medical profesionals. However, it could be a cool benchmark on the state/ on the error assosiated with individuals who do intereact with medical profesionals, but who's disease does not meet the criteria of either probable or confirmed. 

 
